2017년 1월 21일의 토요일..

신경망의 예.

63p :
3.1 퍼셉트론에서 신경망으로

64p :
입력층 - 은닉층 - 출력층으로 나눠짐..

65p :
b는 편향을 나타내는 매개변수 뉴런이 얼마나 쉽게 활성화되느냐를 제어한다.
편향을 명시한다면 w1x1 + w2x2 에 b를 명시할 수 있다

66p :
활성화 함수 : 입력 신호의 총합이 활성화를 일으키는 지 정하는 역할

67p : 뉴런과 노드는 같은 의미.
뉴런을 활성화 하는 모습을 보여줌.

68p :
3.2 활성화함수

계단함수 - 입력값을 경계로 출력이 바뀜. (활성화 함수)
활성화함수를 계단 함수에서 달느 함수로 변경하는 것이 신경망의 세계로 나아가는 열쇠.

신경망에서 이용하는 활성화 함수란..?

- 시그모이드 함수

69 p :
시그모이드함수와의 큰 차이는

70p:
넘파이 배열의 자료형을 변환할 때는 astype() 메서드를 이용

71p~73p : 계단함수를 그래프로 그려봄. 시그모이드를 구현해봄..
시그모이드란 s 자 그래프..

75p :
계단함수와 시그모이드 함수의 공통점은 비선형함수. 신경망에서는 선형함수를 사용해서는 안된다.
선형은 아무리 깊게 해도 선형으로 만들 수 있다...

76p : ReLu

78p : 배열의 차원수는 np.ndim() 으로 알 수 있다.
배열의 형상은 shape 로 알 수 있다.

79p: 행렬곱 np.dot(A,B)






